
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Configuration properties &#8212; Velox  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/nature.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Monitoring" href="monitoring.html" />
    <link rel="prev" title="Window functions" href="functions/spark/window.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="monitoring.html" title="Monitoring"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="functions/spark/window.html" title="Window functions"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Velox  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Configuration properties</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="configuration-properties">
<h1>Configuration properties<a class="headerlink" href="#configuration-properties" title="Permalink to this heading">¶</a></h1>
<section id="generic-configuration">
<h2>Generic Configuration<a class="headerlink" href="#generic-configuration" title="Permalink to this heading">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 18.2%" />
<col style="width: 9.1%" />
<col style="width: 9.1%" />
<col style="width: 63.6%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>preferred_output_batch_bytes</p></td>
<td><p>integer</p></td>
<td><p>10MB</p></td>
<td><p>Preferred size of batches in bytes to be returned by operators from Operator::getOutput. It is used when an
estimate of average row size is known. Otherwise preferred_output_batch_rows is used.</p></td>
</tr>
<tr class="row-odd"><td><p>preferred_output_batch_rows</p></td>
<td><p>integer</p></td>
<td><p>1024</p></td>
<td><p>Preferred number of rows to be returned by operators from Operator::getOutput. It is used when an estimate of
average row size is not known. When the estimate of average row size is known, preferred_output_batch_bytes is used.</p></td>
</tr>
<tr class="row-even"><td><p>max_output_batch_rows</p></td>
<td><p>integer</p></td>
<td><p>10000</p></td>
<td><p>Max number of rows that could be return by operators from Operator::getOutput. It is used when an estimate of
average row size is known and preferred_output_batch_bytes is used to compute the number of output rows.</p></td>
</tr>
<tr class="row-odd"><td><p>table_scan_getoutput_time_limit_ms</p></td>
<td><p>integer</p></td>
<td><p>5000</p></td>
<td><p>TableScan operator will exit getOutput() method after this many milliseconds even if it has no data to return yet. Zero means ‘no time limit’.</p></td>
</tr>
<tr class="row-even"><td><p>abandon_partial_aggregation_min_rows</p></td>
<td><p>integer</p></td>
<td><p>100,000</p></td>
<td><p>Number of input rows to receive before starting to check whether to abandon partial aggregation.</p></td>
</tr>
<tr class="row-odd"><td><p>abandon_partial_aggregation_min_pct</p></td>
<td><p>integer</p></td>
<td><p>80</p></td>
<td><p>Abandons partial aggregation if number of groups equals or exceeds this percentage of the number of input rows.</p></td>
</tr>
<tr class="row-even"><td><p>abandon_partial_topn_row_number_min_rows</p></td>
<td><p>integer</p></td>
<td><p>100,000</p></td>
<td><p>Number of input rows to receive before starting to check whether to abandon partial TopNRowNumber.</p></td>
</tr>
<tr class="row-odd"><td><p>abandon_partial_topn_row_number_min_pct</p></td>
<td><p>integer</p></td>
<td><p>80</p></td>
<td><p>Abandons partial TopNRowNumber if number of output rows equals or exceeds this percentage of the number of input rows.</p></td>
</tr>
<tr class="row-even"><td><p>session_timezone</p></td>
<td><p>string</p></td>
<td></td>
<td><p>User provided session timezone. Stores a string with the actual timezone name, e.g: “America/Los_Angeles”.</p></td>
</tr>
<tr class="row-odd"><td><p>adjust_timestamp_to_session_timezone</p></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>If true, timezone-less timestamp conversions (e.g. string to timestamp, when the string does not specify a timezone)
will be adjusted to the user provided <cite>session_timezone</cite> (if any). For instance: if this option is true and user
supplied “America/Los_Angeles”, then “1970-01-01” will be converted to -28800 instead of 0. Similarly, timestamp
to date conversions will adhere to user ‘session_timezone’, e.g: Timestamp(0) to Date will be -1 (number of days
since epoch) for “America/Los_Angeles”.</p></td>
</tr>
<tr class="row-even"><td><p>track_operator_cpu_usage</p></td>
<td><p>bool</p></td>
<td><p>true</p></td>
<td><p>Whether to track CPU usage for stages of individual operators. Can be expensive when processing small batches,
e.g. &lt; 10K rows.</p></td>
</tr>
<tr class="row-odd"><td><p>hash_adaptivity_enabled</p></td>
<td><p>bool</p></td>
<td><p>true</p></td>
<td><p>If false, the ‘group by’ code is forced to use generic hash mode hashtable.</p></td>
</tr>
<tr class="row-even"><td><p>adaptive_filter_reordering_enabled</p></td>
<td><p>bool</p></td>
<td><p>true</p></td>
<td><p>If true, the conjunction expression can reorder inputs based on the time taken to calculate them.</p></td>
</tr>
<tr class="row-odd"><td><p>max_local_exchange_buffer_size</p></td>
<td><p>integer</p></td>
<td><p>32MB</p></td>
<td><p>Used for backpressure to block local exchange producers when the local exchange buffer reaches or exceeds this size.</p></td>
</tr>
<tr class="row-even"><td><p>exchange.max_buffer_size</p></td>
<td><p>integer</p></td>
<td><p>32MB</p></td>
<td><p>Size of buffer in the exchange client that holds data fetched from other nodes before it is processed.
A larger buffer can increase network throughput for larger clusters and thus decrease query processing time
at the expense of reducing the amount of memory available for other usage.</p></td>
</tr>
<tr class="row-odd"><td><p>merge_exchange.max_buffer_size</p></td>
<td><p>integer</p></td>
<td><p>128MB</p></td>
<td><p>The aggregate buffer size (in bytes) across all exchange clients generated by the merge exchange operator,
responsible for storing data retrieved from various nodes prior to processing. It is divided
equally among all clients and has an upper and lower limit of 32MB and 1MB, respectively, per
client. Enforced approximately, not strictly. A larger size can increase network throughput
for larger clusters and thus decrease query processing time at the expense of reducing the
amount of memory available for other usage.</p></td>
</tr>
<tr class="row-even"><td><p>max_page_partitioning_buffer_size</p></td>
<td><p>integer</p></td>
<td><p>32MB</p></td>
<td><p>The maximum size in bytes for the task’s buffered output when output is partitioned using hash of partitioning keys. See PartitionedOutputNode::Kind::kPartitioned.
The producer Drivers are blocked when the buffered size exceeds this.
The Drivers are resumed when the buffered size goes below OutputBufferManager::kContinuePct (90)% of this.</p></td>
</tr>
<tr class="row-odd"><td><p>max_output_buffer_size</p></td>
<td><p>integer</p></td>
<td><p>32MB</p></td>
<td><p>The maximum size in bytes for the task’s buffered output.
The producer Drivers are blocked when the buffered size exceeds this.
The Drivers are resumed when the buffered size goes below OutputBufferManager::kContinuePct (90)% of this.</p></td>
</tr>
<tr class="row-even"><td><p>min_table_rows_for_parallel_join_build</p></td>
<td><p>integer</p></td>
<td><p>1000</p></td>
<td><p>The minimum number of table rows that can trigger the parallel hash join table build.</p></td>
</tr>
<tr class="row-odd"><td><p>debug.validate_output_from_operators</p></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>If set to true, then during execution of tasks, the output vectors of every operator are validated for consistency.
This is an expensive check so should only be used for debugging. It can help debug issues where malformed vector
cause failures or crashes by helping identify which operator is generating them.</p></td>
</tr>
<tr class="row-even"><td><p>enable_expression_evaluation_cache</p></td>
<td><p>bool</p></td>
<td><p>true</p></td>
<td><p>Whether to enable caches in expression evaluation. If set to true, optimizations including vector pools and
evalWithMemo are enabled.</p></td>
</tr>
<tr class="row-odd"><td><p>max_shared_subexpr_results_cached</p></td>
<td><p>integer</p></td>
<td><p>10</p></td>
<td><p>For a given shared subexpression, the maximum distinct sets of inputs we cache results for. Lambdas can call
the same expression with different inputs many times, causing the results we cache to explode in size. Putting
a limit contains the memory usage.</p></td>
</tr>
<tr class="row-even"><td><p>driver_cpu_time_slice_limit_ms</p></td>
<td><p>integer</p></td>
<td><p>0</p></td>
<td><p>If it is not zero, specifies the time limit that a driver can continuously
run on a thread before yield. If it is zero, then it no limit.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="expression-evaluation-configuration">
<span id="expression-evaluation-conf"></span><h2>Expression Evaluation Configuration<a class="headerlink" href="#expression-evaluation-configuration" title="Permalink to this heading">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 18.2%" />
<col style="width: 9.1%" />
<col style="width: 9.1%" />
<col style="width: 63.6%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>expression.eval_simplified</p></td>
<td><p>boolean</p></td>
<td><p>false</p></td>
<td><p>Whether to use the simplified expression evaluation path.</p></td>
</tr>
<tr class="row-odd"><td><p>expression.track_cpu_usage</p></td>
<td><p>boolean</p></td>
<td><p>false</p></td>
<td><p>Whether to track CPU usage for individual expressions (supported by call and cast expressions). Can be expensive
when processing small batches, e.g. &lt; 10K rows.</p></td>
</tr>
<tr class="row-even"><td><p>legacy_cast</p></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>Enables legacy CAST semantics if set to true. CAST(timestamp AS varchar) uses ‘T’ as separator between date and
time (instead of a space), and the year part is not padded.</p></td>
</tr>
<tr class="row-odd"><td><p>cast_match_struct_by_name</p></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>This flag makes the Row conversion to by applied in a way that the casting row field are matched by name instead of position.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="memory-management">
<h2>Memory Management<a class="headerlink" href="#memory-management" title="Permalink to this heading">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 18.2%" />
<col style="width: 9.1%" />
<col style="width: 9.1%" />
<col style="width: 63.6%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>max_partial_aggregation_memory</p></td>
<td><p>integer</p></td>
<td><p>16MB</p></td>
<td><p>Maximum amount of memory in bytes for partial aggregation results. Increasing this value can result in less
network transfer and lower CPU utilization by allowing more groups to be kept locally before being flushed,
at the cost of additional memory usage.</p></td>
</tr>
<tr class="row-odd"><td><p>max_extended_partial_aggregation_memory</p></td>
<td><p>integer</p></td>
<td><p>16MB</p></td>
<td><p>Maximum amount of memory in bytes for partial aggregation results if cardinality reduction is below
<cite>partial_aggregation_reduction_ratio_threshold</cite>. Every time partial aggregate results size reaches
<cite>max_partial_aggregation_memory</cite> bytes, the results are flushed. If cardinality reduction is below
<cite>partial_aggregation_reduction_ratio_threshold</cite>,
i.e. <cite>number of result rows / number of input rows &gt; partial_aggregation_reduction_ratio_threshold</cite>,
memory limit for partial aggregation is automatically doubled up to <cite>max_extended_partial_aggregation_memory</cite>.
This adaptation is disabled by default, since the value of <cite>max_extended_partial_aggregation_memory</cite> equals the
value of <cite>max_partial_aggregation_memory</cite>. Specify higher value for <cite>max_extended_partial_aggregation_memory</cite> to enable.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="spilling">
<h2>Spilling<a class="headerlink" href="#spilling" title="Permalink to this heading">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 18.2%" />
<col style="width: 9.1%" />
<col style="width: 9.1%" />
<col style="width: 63.6%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>spill_enabled</p></td>
<td><p>boolean</p></td>
<td><p>false</p></td>
<td><p>Spill memory to disk to avoid exceeding memory limits for the query.</p></td>
</tr>
<tr class="row-odd"><td><p>aggregation_spill_enabled</p></td>
<td><p>boolean</p></td>
<td><p>true</p></td>
<td><p>When <cite>spill_enabled</cite> is true, determines whether HashAggregation operator can spill to disk under memory pressure.</p></td>
</tr>
<tr class="row-even"><td><p>join_spill_enabled</p></td>
<td><p>boolean</p></td>
<td><p>true</p></td>
<td><p>When <cite>spill_enabled</cite> is true, determines whether HashBuild and HashProbe operators can spill to disk under memory pressure.</p></td>
</tr>
<tr class="row-odd"><td><p>order_by_spill_enabled</p></td>
<td><p>boolean</p></td>
<td><p>true</p></td>
<td><p>When <cite>spill_enabled</cite> is true, determines whether OrderBy operator can spill to disk under memory pressure.</p></td>
</tr>
<tr class="row-even"><td><p>window_spill_enabled</p></td>
<td><p>boolean</p></td>
<td><p>true</p></td>
<td><p>When <cite>spill_enabled</cite> is true, determines whether Window operator can spill to disk under memory pressure.</p></td>
</tr>
<tr class="row-odd"><td><p>row_number_spill_enabled</p></td>
<td><p>boolean</p></td>
<td><p>true</p></td>
<td><p>When <cite>spill_enabled</cite> is true, determines whether RowNumber operator can spill to disk under memory pressure.</p></td>
</tr>
<tr class="row-even"><td><p>topn_row_number_spill_enabled</p></td>
<td><p>boolean</p></td>
<td><p>true</p></td>
<td><p>When <cite>spill_enabled</cite> is true, determines whether TopNRowNumber operator can spill to disk under memory pressure.</p></td>
</tr>
<tr class="row-odd"><td><p>writer_spill_enabled</p></td>
<td><p>boolean</p></td>
<td><p>true</p></td>
<td><p>When <cite>writer_spill_enabled</cite> is true, determines whether TableWriter operator can flush the buffered data to disk
under memory pressure.</p></td>
</tr>
<tr class="row-even"><td><p>aggregation_spill_memory_threshold</p></td>
<td><p>integer</p></td>
<td><p>0</p></td>
<td><p>Maximum amount of memory in bytes that a final aggregation can use before spilling. 0 means unlimited.</p></td>
</tr>
<tr class="row-odd"><td><p>join_spill_memory_threshold</p></td>
<td><p>integer</p></td>
<td><p>0</p></td>
<td><p>Maximum amount of memory in bytes that a hash join build side can use before spilling. 0 means unlimited.</p></td>
</tr>
<tr class="row-even"><td><p>order_by_spill_memory_threshold</p></td>
<td><p>integer</p></td>
<td><p>0</p></td>
<td><p>Maximum amount of memory in bytes that an order by can use before spilling. 0 means unlimited.</p></td>
</tr>
<tr class="row-odd"><td><p>writer_flush_threshold_bytes</p></td>
<td><p>integer</p></td>
<td><p>96MB</p></td>
<td><p>Minimum memory footprint size required to reclaim memory from a file writer by flushing its buffered data to disk.</p></td>
</tr>
<tr class="row-even"><td><p>min_spillable_reservation_pct</p></td>
<td><p>integer</p></td>
<td><p>5</p></td>
<td><p>The minimal available spillable memory reservation in percentage of the current memory usage. Suppose the current
memory usage size of M, available memory reservation size of N and min reservation percentage of P,
if M * P / 100 &gt; N, then spiller operator needs to grow the memory reservation with percentage of
‘spillable_reservation_growth_pct’ (see below). This ensures we have sufficient amount of memory reservation to
process the large input outlier.</p></td>
</tr>
<tr class="row-odd"><td><p>spillable_reservation_growth_pct</p></td>
<td><p>integer</p></td>
<td><p>10</p></td>
<td><p>The spillable memory reservation growth percentage of the current memory usage. Suppose a growth percentage of N
and the current memory usage size of M, the next memory reservation size will be M * (1 + N / 100). After growing
the memory reservation K times, the memory reservation size will be M * (1 + N / 100) ^ K. Hence the memory
reservation grows along a series of powers of (1 + N / 100). If the memory reservation fails, it starts spilling.</p></td>
</tr>
<tr class="row-even"><td><p>max_spill_level</p></td>
<td><p>integer</p></td>
<td><p>1</p></td>
<td><p>The maximum allowed spilling level with zero being the initial spilling level. Applies to hash join build
spilling which might use recursive spilling when the build table is very large. -1 means unlimited.
In this case an extremely large query might run out of spilling partition bits. The max spill level
can be used to prevent a query from using too much io and cpu resources.</p></td>
</tr>
<tr class="row-odd"><td><p>max_spill_run_rows</p></td>
<td><p>integer</p></td>
<td><p>12582912</p></td>
<td><p>The max number of rows to fill and spill for each spill run. This is used to cap the memory used for spilling.
If it is zero, then there is no limit and spilling might run out of memory. Based on offline test results, the
default value is set to 12 million rows which uses ~128MB memory when to fill a spill run.
Relation between spill rows and memory usage are as follows:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">12</span> <span class="pre">million</span> <span class="pre">rows:</span> <span class="pre">128</span> <span class="pre">MB</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">30</span> <span class="pre">million</span> <span class="pre">rows:</span> <span class="pre">256</span> <span class="pre">MB</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">60</span> <span class="pre">million</span> <span class="pre">rows:</span> <span class="pre">512</span> <span class="pre">MB</span></code></p></li>
</ul>
</div></blockquote>
</td>
</tr>
<tr class="row-even"><td><p>max_spill_file_size</p></td>
<td><p>integer</p></td>
<td><p>0</p></td>
<td><p>The maximum allowed spill file size. Zero means unlimited.</p></td>
</tr>
<tr class="row-odd"><td><p>max_spill_bytes</p></td>
<td><p>integer</p></td>
<td><p>107374182400</p></td>
<td><p>The max spill bytes limit set for each query. This is used to cap the storage used for spilling.
If it is zero, then there is no limit and spilling might exhaust the storage or takes too long to run.
The default value is set to 100 GB.</p></td>
</tr>
<tr class="row-even"><td><p>spill_write_buffer_size</p></td>
<td><p>integer</p></td>
<td><p>4MB</p></td>
<td><p>The maximum size in bytes to buffer the serialized spill data before write to disk for IO efficiency.
If set to zero, buffering is disabled.</p></td>
</tr>
<tr class="row-odd"><td><p>min_spill_run_size</p></td>
<td><p>integer</p></td>
<td><p>256MB</p></td>
<td><p>The minimum spill run size (bytes) limit used to select partitions for spilling. The spiller tries to spill a
previously spilled partitions if its data size exceeds this limit, otherwise it spills the partition with most data.
If the limit is zero, then the spiller always spills a previously spilled partition if it has any data. This is
to avoid spill from a partition with a small amount of data which might result in generating too many small
spilled files.</p></td>
</tr>
<tr class="row-even"><td><p>spill_compression_codec</p></td>
<td><p>string</p></td>
<td><p>none</p></td>
<td><p>Specifies the compression algorithm type to compress the spilled data before write to disk to trade CPU for IO
efficiency. The supported compression codecs are: ZLIB, SNAPPY, LZO, ZSTD, LZ4 and GZIP.
NONE means no compression.</p></td>
</tr>
<tr class="row-odd"><td><p>spiller_start_partition_bit</p></td>
<td><p>integer</p></td>
<td><p>29</p></td>
<td><p>The start partition bit which is used with <cite>spiller_partition_bits</cite> together to calculate the spilling partition number.</p></td>
</tr>
<tr class="row-even"><td><p>spiller_num_partition_bits</p></td>
<td><p>integer</p></td>
<td><p>3</p></td>
<td><p>The number of bits (N) used to calculate the spilling partition number for hash join and RowNumber: 2 ^ N. At the moment the maximum
value is 3, meaning we only support up to 8-way spill partitioning.ing.</p></td>
</tr>
<tr class="row-odd"><td><p>testing.spill_pct</p></td>
<td><p>integer</p></td>
<td><p>0</p></td>
<td><p>Percentage of aggregation or join input batches that will be forced to spill for testing. 0 means no extra spilling.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="table-scan">
<h2>Table Scan<a class="headerlink" href="#table-scan" title="Permalink to this heading">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 18.2%" />
<col style="width: 9.1%" />
<col style="width: 9.1%" />
<col style="width: 63.6%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>max_split_preload_per_driver</p></td>
<td><p>integer</p></td>
<td><p>2</p></td>
<td><p>Maximum number of splits to preload per driver. Set to 0 to disable preloading.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="table-writer">
<h2>Table Writer<a class="headerlink" href="#table-writer" title="Permalink to this heading">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 18.2%" />
<col style="width: 9.1%" />
<col style="width: 9.1%" />
<col style="width: 63.6%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>task_writer_count</p></td>
<td><p>integer</p></td>
<td><p>1</p></td>
<td><p>The number of parallel table writer threads per task.</p></td>
</tr>
<tr class="row-odd"><td><p>task_partitioned_writer_count</p></td>
<td><p>integer</p></td>
<td><p>task_writer_count</p></td>
<td><p>The number of parallel table writer threads per task for bucketed table writes. If not set, use ‘task_writer_count’ as default.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="hive-connector">
<h2>Hive Connector<a class="headerlink" href="#hive-connector" title="Permalink to this heading">¶</a></h2>
<p>Hive Connector config is initialized on velox runtime startup and is shared among queries as the default config.
Each query can override the config by setting corresponding query session properties such as in Prestissimo.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15.4%" />
<col style="width: 15.4%" />
<col style="width: 7.7%" />
<col style="width: 7.7%" />
<col style="width: 53.8%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Configuration Property Name</p></th>
<th class="head"><p>Session Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>hive.max-partitions-per-writers</p></td>
<td></td>
<td><p>integer</p></td>
<td><p>100</p></td>
<td><p>Maximum number of (bucketed) partitions per a single table writer instance.</p></td>
</tr>
<tr class="row-odd"><td><p>insert-existing-partitions-behavior</p></td>
<td><p>insert_existing_partitions_behavior</p></td>
<td><p>string</p></td>
<td><p>ERROR</p></td>
<td><p><strong>Allowed values:</strong> <code class="docutils literal notranslate"><span class="pre">OVERWRITE</span></code>, <code class="docutils literal notranslate"><span class="pre">ERROR</span></code>. The behavior on insert existing partitions. This property only derives
the update mode field of the table writer operator output. <code class="docutils literal notranslate"><span class="pre">OVERWRITE</span></code>
sets the update mode to indicate overwriting a partition if exists. <code class="docutils literal notranslate"><span class="pre">ERROR</span></code> sets the update mode to indicate
error throwing if writing to an existing partition.</p></td>
</tr>
<tr class="row-even"><td><p>hive.immutable-partitions</p></td>
<td></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>True if appending data to an existing unpartitioned table is allowed. Currently this configuration does not
support appending to existing partitions.</p></td>
</tr>
<tr class="row-odd"><td><p>file-column-names-read-as-lower-case</p></td>
<td></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>True if reading the source file column names as lower case, and planner should guarantee
the input column name and filter is also lower case to achive case-insensitive read.</p></td>
</tr>
<tr class="row-even"><td><p>partition_path_as_lower_case</p></td>
<td></td>
<td><p>bool</p></td>
<td><p>true</p></td>
<td><p>If true, the partition directory will be converted to lowercase when executing a table write operation.</p></td>
</tr>
<tr class="row-odd"><td><p>ignore_missing_files</p></td>
<td></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>If true, splits that refer to missing files don’t generate errors and are processed as empty splits.</p></td>
</tr>
<tr class="row-even"><td><p>max-coalesced-bytes</p></td>
<td></td>
<td><p>integer</p></td>
<td><p>128MB</p></td>
<td><p>Maximum size in bytes to coalesce requests to be fetched in a single request.</p></td>
</tr>
<tr class="row-odd"><td><p>max-coalesced-distance-bytes</p></td>
<td></td>
<td><p>integer</p></td>
<td><p>512KB</p></td>
<td><p>Maximum distance in bytes between chunks to be fetched that may be coalesced into a single request.</p></td>
</tr>
<tr class="row-even"><td><p>load-quantum</p></td>
<td></td>
<td><p>integer</p></td>
<td><p>8MB</p></td>
<td><p>Define the size of each coalesce load request. E.g. in Parquet scan, if it’s bigger than rowgroup size then the whole row group can be fetched together. Otherwise, the row group will be fetched column chunk by column chunk</p></td>
</tr>
<tr class="row-odd"><td><p>num-cached-file-handles</p></td>
<td></td>
<td><p>integer</p></td>
<td><p>20000</p></td>
<td><p>Maximum number of entries in the file handle cache. The value must be non-negative. Zero value
indicates infinite cache capacity.</p></td>
</tr>
<tr class="row-even"><td><p>file-handle-cache-enabled</p></td>
<td></td>
<td><p>bool</p></td>
<td><p>true</p></td>
<td><p>Enables caching of file handles if true. Disables caching if false. File handle cache should be
disabled if files are not immutable, i.e. file content may change while file path stays the same.</p></td>
</tr>
<tr class="row-odd"><td><p>sort-writer-max-output-rows</p></td>
<td><p>sort_writer_max_output_rows</p></td>
<td><p>integer</p></td>
<td><p>1024</p></td>
<td><p>Maximum number of rows for sort writer in one batch of output. This is to limit the memory usage of sort writer.</p></td>
</tr>
<tr class="row-even"><td><p>sort-writer-max-output-bytes</p></td>
<td><p>sort_writer_max_output_bytes</p></td>
<td><p>string</p></td>
<td><p>10MB</p></td>
<td><p>Maximum bytes for sort writer in one batch of output. This is to limit the memory usage of sort writer.</p></td>
</tr>
<tr class="row-odd"><td><p>file-preload-threshold</p></td>
<td></td>
<td><p>integer</p></td>
<td><p>8MB</p></td>
<td><p>Usually Velox fetches the meta data firstly then fetch the rest of file. But if the file is very small, Velox can fetch the whole file directly to avoid multiple IO requests.
The parameter controls the threshold when whole file is fetched.</p></td>
</tr>
<tr class="row-even"><td><p>footer-estimated-size</p></td>
<td></td>
<td><p>integer</p></td>
<td><p>1MB</p></td>
<td><p>Define the estimation of footer size in ORC and Parquet format. The footer data includes version, schema, and meta data for every columns which may or may not need to be fetched later.
The parameter controls the size when footer is fetched each time. Bigger value can decrease the IO requests but may fetch more useless meta data.</p></td>
</tr>
<tr class="row-odd"><td><p>hive.orc.writer.stripe-max-size</p></td>
<td><p>orc_optimized_writer_max_stripe_size</p></td>
<td><p>string</p></td>
<td><p>64M</p></td>
<td><p>Maximum stripe size in orc writer.</p></td>
</tr>
<tr class="row-even"><td><p>hive.orc.writer.dictionary-max-memory</p></td>
<td><p>orc_optimized_writer_max_dictionary_memory</p></td>
<td><p>string</p></td>
<td><p>16M</p></td>
<td><p>Maximum dictionary memory that can be used in orc writer.</p></td>
</tr>
<tr class="row-odd"><td><p>hive.parquet.writer.timestamp-unit</p></td>
<td><p>hive.parquet.writer.timestamp_unit</p></td>
<td><p>tinyint</p></td>
<td><p>9</p></td>
<td><p>Timestamp unit used when writing timestamps into Parquet through Arrow bridge.
Valid values are 0 (second), 3 (millisecond), 6 (microsecond), 9 (nanosecond).</p></td>
</tr>
</tbody>
</table>
<section id="amazon-s3-configuration">
<h3><code class="docutils literal notranslate"><span class="pre">Amazon</span> <span class="pre">S3</span> <span class="pre">Configuration</span></code><a class="headerlink" href="#amazon-s3-configuration" title="Permalink to this heading">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 25.0%" />
<col style="width: 8.3%" />
<col style="width: 8.3%" />
<col style="width: 58.3%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>hive.s3.use-instance-credentials</p></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>Use the EC2 metadata service to retrieve API credentials. This works with IAM roles in EC2.</p></td>
</tr>
<tr class="row-odd"><td><p>hive.s3.aws-access-key</p></td>
<td><p>string</p></td>
<td></td>
<td><p>Default AWS access key to use.</p></td>
</tr>
<tr class="row-even"><td><p>hive.s3.aws-secret-key</p></td>
<td><p>string</p></td>
<td></td>
<td><p>Default AWS secret key to use.</p></td>
</tr>
<tr class="row-odd"><td><p>hive.s3.endpoint</p></td>
<td><p>string</p></td>
<td></td>
<td><p>The S3 storage endpoint server. This can be used to connect to an S3-compatible storage system instead of AWS.</p></td>
</tr>
<tr class="row-even"><td><p>hive.s3.path-style-access</p></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>Use path-style access for all requests to the S3-compatible storage. This is for S3-compatible storage that
doesn’t support virtual-hosted-style access.</p></td>
</tr>
<tr class="row-odd"><td><p>hive.s3.ssl.enabled</p></td>
<td><p>bool</p></td>
<td><p>true</p></td>
<td><p>Use HTTPS to communicate with the S3 API.</p></td>
</tr>
<tr class="row-even"><td><p>hive.s3.log-level</p></td>
<td><p>string</p></td>
<td><p>FATAL</p></td>
<td><p><strong>Allowed values:</strong> “OFF”, “FATAL”, “ERROR”, “WARN”, “INFO”, “DEBUG”, “TRACE”
Granularity of logging generated by the AWS C++ SDK library.</p></td>
</tr>
<tr class="row-odd"><td><p>hive.s3.iam-role</p></td>
<td><p>string</p></td>
<td></td>
<td><p>IAM role to assume.</p></td>
</tr>
<tr class="row-even"><td><p>hive.s3.iam-role-session-name</p></td>
<td><p>string</p></td>
<td><p>velox-session</p></td>
<td><p>Session name associated with the IAM role.</p></td>
</tr>
<tr class="row-odd"><td><p>hive.s3.use-proxy-from-env</p></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>Utilize the configuration of the environment variables http_proxy, https_proxy, and no_proxy for use with the S3 API.</p></td>
</tr>
<tr class="row-even"><td><p>hive.s3.connect-timeout</p></td>
<td><p>string</p></td>
<td></td>
<td><p>Socket connect timeout.</p></td>
</tr>
<tr class="row-odd"><td><p>hive.s3.socket-timeout</p></td>
<td><p>string</p></td>
<td></td>
<td><p>Socket read timeout.</p></td>
</tr>
<tr class="row-even"><td><p>hive.s3.max-connections</p></td>
<td><p>integer</p></td>
<td></td>
<td><p>Maximum concurrent TCP connections for a single http client.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="google-cloud-storage-configuration">
<h3><code class="docutils literal notranslate"><span class="pre">Google</span> <span class="pre">Cloud</span> <span class="pre">Storage</span> <span class="pre">Configuration</span></code><a class="headerlink" href="#google-cloud-storage-configuration" title="Permalink to this heading">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 27.3%" />
<col style="width: 9.1%" />
<col style="width: 9.1%" />
<col style="width: 54.5%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>hive.gcs.endpoint</p></td>
<td><p>string</p></td>
<td></td>
<td><p>The GCS storage endpoint server.</p></td>
</tr>
<tr class="row-odd"><td><p>hive.gcs.scheme</p></td>
<td><p>string</p></td>
<td></td>
<td><p>The GCS storage scheme, https for default credentials.</p></td>
</tr>
<tr class="row-even"><td><p>hive.gcs.credentials</p></td>
<td><p>string</p></td>
<td></td>
<td><p>The GCS service account configuration as json string.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="azure-blob-storage-configuration">
<h3><code class="docutils literal notranslate"><span class="pre">Azure</span> <span class="pre">Blob</span> <span class="pre">Storage</span> <span class="pre">Configuration</span></code><a class="headerlink" href="#azure-blob-storage-configuration" title="Permalink to this heading">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 27.3%" />
<col style="width: 9.1%" />
<col style="width: 9.1%" />
<col style="width: 54.5%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>fs.azure.account.key.&lt;storage-account&gt;.dfs.core.windows.net</p></td>
<td><p>string</p></td>
<td></td>
<td><p>The credentials to access the specific Azure Blob Storage account, replace &lt;storage-account&gt; with the name of your Azure Storage account.
This property aligns with how Spark configures Azure account key credentials for accessing Azure storage, by setting this property multiple
times with different storage account names, you can access multiple Azure storage accounts.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="presto-specific-configuration">
<h2>Presto-specific Configuration<a class="headerlink" href="#presto-specific-configuration" title="Permalink to this heading">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 18.2%" />
<col style="width: 9.1%" />
<col style="width: 9.1%" />
<col style="width: 63.6%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>presto.array_agg.ignore_nulls</p></td>
<td><p>bool</p></td>
<td><p>false</p></td>
<td><p>If true, <code class="docutils literal notranslate"><span class="pre">array_agg</span></code> function ignores null inputs.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="spark-specific-configuration">
<h2>Spark-specific Configuration<a class="headerlink" href="#spark-specific-configuration" title="Permalink to this heading">¶</a></h2>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Configuration properties</a><ul>
<li><a class="reference internal" href="#generic-configuration">Generic Configuration</a></li>
<li><a class="reference internal" href="#expression-evaluation-configuration">Expression Evaluation Configuration</a></li>
<li><a class="reference internal" href="#memory-management">Memory Management</a></li>
<li><a class="reference internal" href="#spilling">Spilling</a></li>
<li><a class="reference internal" href="#table-scan">Table Scan</a></li>
<li><a class="reference internal" href="#table-writer">Table Writer</a></li>
<li><a class="reference internal" href="#hive-connector">Hive Connector</a><ul>
<li><a class="reference internal" href="#amazon-s3-configuration"><code class="docutils literal notranslate"><span class="pre">Amazon</span> <span class="pre">S3</span> <span class="pre">Configuration</span></code></a></li>
<li><a class="reference internal" href="#google-cloud-storage-configuration"><code class="docutils literal notranslate"><span class="pre">Google</span> <span class="pre">Cloud</span> <span class="pre">Storage</span> <span class="pre">Configuration</span></code></a></li>
<li><a class="reference internal" href="#azure-blob-storage-configuration"><code class="docutils literal notranslate"><span class="pre">Azure</span> <span class="pre">Blob</span> <span class="pre">Storage</span> <span class="pre">Configuration</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#presto-specific-configuration">Presto-specific Configuration</a></li>
<li><a class="reference internal" href="#spark-specific-configuration">Spark-specific Configuration</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="functions/spark/window.html"
                          title="previous chapter">Window functions</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="monitoring.html"
                          title="next chapter">Monitoring</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/configs.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="monitoring.html" title="Monitoring"
             >next</a> |</li>
        <li class="right" >
          <a href="functions/spark/window.html" title="Window functions"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Velox  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Configuration properties</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright TBD.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.2.0.
    </div>
  </body>
</html>